{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv; load_dotenv()\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import datetime as dt, json\n",
    "\n",
    "client = OpenAI()\n",
    "out = Path(\"../data/outputs\"); out.mkdir(parents=True, exist_ok=True)\n",
    "TS = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",  # use a working model on your account\n",
    "    input=\"Give me 3 AI features for vacation rental hosts (one line each).\"\n",
    ")\n",
    "print(r.output_text)\n",
    "(out / f\"resp_{TS}.txt\").write_text(r.output_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Give me 3 AI features for vacation rental hosts (one line each).\"}],\n",
    "    temperature=0.7,\n",
    ")\n",
    "text = r.choices[0].message.content\n",
    "print(text)\n",
    "(out / f\"chat_{TS}.txt\").write_text(text)\n",
    "print(\"usage:\", getattr(r, \"usage\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"system\",\"content\":\"You are a concise product assistant.\"},\n",
    "    {\"role\":\"user\",\"content\":\"Propose 3 features to reduce guest support load.\"}\n",
    "]\n",
    "r1 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    messages=messages)\n",
    "\n",
    "print(\"A1:\", r1.choices[0].message.content)\n",
    "\n",
    "messages.append({\"role\":\"assistant\",\"content\": r1.choices[0].message.content})\n",
    "messages.append({\"role\":\"user\",\"content\":\"Great. Turn #2 into a one-week sprint plan with tasks.\"})\n",
    "\n",
    "r2 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    messages=messages)\n",
    "\n",
    "print(\"A2:\", r2.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Turn 1\n",
    "r1 = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    instructions=\"You are a concise product assistant.\",\n",
    "    input=\"Propose 3 features to reduce guest support load.\",\n",
    "    store=True,  # keep state so we can chain\n",
    ")\n",
    "print(r1.output_text)\n",
    "\n",
    "# Turn 2 (continues the same conversation)\n",
    "r2 = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    previous_response_id=r1.id,  # <-- carries context from r1\n",
    "    input=\"Great. Turn #2 into a one-week sprint plan with tasks.\"\n",
    ")\n",
    "print(r2.output_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a 1-sentence positioning statement for a vacation rental AI co-pilot.\"\n",
    "for t in [0.0, 0.3, 0.7, 1.0]:\n",
    "    r = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":\"Be crisp, avoid hype, <12 words.\"},\n",
    "            {\"role\":\"user\",\"content\": prompt},\n",
    "        ],\n",
    "        temperature=t,\n",
    "    )\n",
    "    print(f\"\\nTemp {t}: {r.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format={\"type\":\"json_object\"},\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Return JSON with keys title, problem, impact(1-10) for 1 feature idea.\"}],\n",
    "    temperature=0.3\n",
    ")\n",
    "data = json.loads(r.choices[0].message.content)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\":\"system\",\"content\":\"You are a concise product assistant.\"},\n",
    "    {\"role\":\"user\",\"content\":\"Propose 3 features to reduce guest support load.\"}\n",
    "]\n",
    "r1 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    messages=messages)\n",
    "\n",
    "print(\"A1:\", r1.choices[0].message.content)\n",
    "\n",
    "messages.append({\"role\":\"assistant\",\"content\": r1.choices[0].message.content})\n",
    "messages.append({\"role\":\"user\",\"content\":\"Return JSON with keys title, problem, impact(1-10) for 1 feature idea.\"})\n",
    "\n",
    "r2 = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format={\"type\":\"json_object\"}, \n",
    "    messages=messages,\n",
    "    temperature=0.3)\n",
    "\n",
    "\n",
    "data = json.loads(r2.choices[0].message.content)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(name, obj):\n",
    "    p = out / f\"{name}_{TS}.json\"\n",
    "    p.write_text(json.dumps(obj, indent=2))\n",
    "    return p\n",
    "\n",
    "log = {\n",
    "    \"ts\": TS,\n",
    "    \"patterns\": [\"responses\", \"chat\", \"multi_turn\", \"temp_sweep\", \"json_lite\"],\n",
    "}\n",
    "print(\"Saved log to:\", save_json(\"day2_patterns_log\", log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv; load_dotenv()\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import json, jsonschema, pandas as pd\n",
    "\n",
    "client = OpenAI()\n",
    "OUT = Path(\"../data/outputs\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "TS = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def save_json(path: Path, obj: dict):\n",
    "    path.write_text(json.dumps(obj, indent=2))\n",
    "    return path.resolve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"topic\": {\"type\": \"string\"},\n",
    "        \"ideas\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\":\"object\",\n",
    "                \"properties\":{\n",
    "                    \"title\":  {\"type\":\"string\"},\n",
    "                    \"problem\":{\"type\":\"string\"},\n",
    "                    \"impact\": {\"type\":\"integer\", \"minimum\":1, \"maximum\":10},\n",
    "                    \"effort\": {\"type\":\"integer\", \"minimum\":1, \"maximum\":10}\n",
    "                },\n",
    "                \"required\": [\"title\",\"problem\",\"impact\",\"effort\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"topic\",\"ideas\"]\n",
    "}\n",
    "SCHEMA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv; load_dotenv()\n",
    "from openai import OpenAI\n",
    "import json, jsonschema\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "client = OpenAI()\n",
    "OUT = Path(\"../data/outputs\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "TS = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "topic = \"Vacation rental software\"\n",
    "n = 5\n",
    "\n",
    "# Wrap your schema for Structured Outputs\n",
    "structured_format = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"ideas_schema\",\n",
    "        \"schema\": SCHEMA,     # <- the dict you defined earlier\n",
    "        \"strict\": True        # enforce the schema\n",
    "    }\n",
    "}\n",
    "\n",
    "instructions = \"You are a concise product ideation assistant.\"\n",
    "prompt = f'Generate exactly {n} ideas for topic \"{topic}\". Return JSON only—no prose.'\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",      # use a model available on your account\n",
    "    instructions=instructions,\n",
    "    input=prompt,\n",
    "    response_format=structured_format,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "raw = resp.output_text\n",
    "print(\"RAW preview:\", raw[:300], \"...\\n\")\n",
    "\n",
    "data = json.loads(raw)                # parse JSON\n",
    "jsonschema.validate(data, SCHEMA)     # validate against your schema\n",
    "print(\"✅ Valid JSON with\", len(data[\"ideas\"]), \"ideas\")\n",
    "\n",
    "# Save\n",
    "out_json = OUT / f\"ideas_structured_{TS}.json\"\n",
    "out_json.write_text(json.dumps(data, indent=2))\n",
    "out_json\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
